#!/usr/bin/env python

# Copyright European Organization for Nuclear Research (CERN)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# You may not use this file except in compliance with the License.
# You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
#
# Authors:
# - Mario Lassnig, <mario.lassnig@cern.ch>, 2012-2014
# - Vincent Garonne, <vincent.garonne@cern.ch>, 2012-2013
# - Thomas Beermann, <thomas.beermann@cern.ch>, 2012
# - Yun-Pin Sun, <yun-pin.sun@cern.ch>, 2013
# - Cedric Serfon <cedric.serfon@cern.ch>, 2013-2015
# - Martin Barisits <martin.barisits@cern.ch>, 2013-2015
# - Joaquin Bogado <joaquin.bogado@cern.ch>, 2014
# - Evangelia Liotiri <evangelia.liotiri@cern.ch>, 2015

"""
    Rucio CLI.
"""

import argcomplete
import argparse
import logging
import os
import random
import sys
import time
import traceback

from functools import wraps

from rucio.client import Client
from rucio import version
from rucio.common.exception import DataIdentifierAlreadyExists, Duplicate, FileAlreadyExists, AccessDenied, RessourceTemporaryUnavailable, DataIdentifierNotFound, InvalidObject, RSENotFound, InvalidRSEExpression, DuplicateContent
from rucio.common.utils import adler32, generate_uuid
from rucio.rse import rsemanager as rsemgr

SUCCESS = 0
FAILURE = 1

DEFAULT_SECURE_PORT = 443
DEFAULT_PORT = 80


logger = logging.getLogger("user")


def setup_logger(logger):
    logger.setLevel(logging.INFO)
    hdlr = logging.StreamHandler()

    def emit_decorator(fn):
        def func(*args):
            levelno = args[0].levelno
            if(levelno >= logging.CRITICAL):
                color = '\033[31;1m'
            elif(levelno >= logging.ERROR):
                color = '\033[31;1m'
            elif(levelno >= logging.WARNING):
                color = '\033[33;1m'
            elif(levelno >= logging.INFO):
                color = '\033[32;1m'
            elif(levelno >= logging.DEBUG):
                color = '\033[36;1m'
            else:
                color = '\033[0m'
            formatter = logging.Formatter('{0}%(asctime)s %(levelname)s [%(message)s]\033[0m'.format(color))
            hdlr.setFormatter(formatter)
            return fn(*args)
        return func
    hdlr.emit = emit_decorator(hdlr.emit)
    logger.addHandler(hdlr)

setup_logger(logger)


def extract_scope(did):
    try:
        scope, name = did.split(':')
    except ValueError, e:
        raise InvalidObject('Cannot extract the scope and name from {0} : [{1}]'.format(did, e))
    return scope, name


def exception_handler(function):
    @wraps(function)
    def new_funct(*args, **kwargs):
        try:
            return function(*args, **kwargs)
        except InvalidObject, e:
            logger.error(e)
            return FAILURE
        except DataIdentifierNotFound, e:
            logger.error(e)
            logger.debug('This means that the Data IDentifier you provided is not known by Rucio.')
            return FAILURE
        except AccessDenied, e:
            logger.error(e)
            logger.debug('This error is a permission issue. You cannot run this command with your account.')
            return FAILURE
        except DataIdentifierAlreadyExists, e:
            logger.error(e)
            logger.debug('This means that the data IDentifier you try to add is already registered in Rucio.')
            return FAILURE
        except RSENotFound, e:
            logger.error(e)
            logger.debug('This means that the Rucio Storage Element you provided is not known by Rucio.')
            return FAILURE
        except InvalidRSEExpression, e:
            logger.error(e)
            logger.debug('This means the RSE expression you provided is not syntactically correct.')
            return FAILURE
        except DuplicateContent, e:
            logger.error(e)
            logger.debug('This means that the DID you want to attach is already in the target DID.')
            return FAILURE
        except TypeError, e:
            logger.error(e)
            logger.debug('This means the parameter you passed has a wrong type.')
            return FAILURE
        except Exception, e:
            logger.error(e)
            logger.error('Rucio exited with an unexpected/unknown error, please provide the traceback below to the developpers.')
            logger.debug(traceback.format_exc())
            return FAILURE
    return new_funct


def get_client(args):
    """
    Returns a new client object.
    """
    if args.auth_strategy == 'userpass':
        creds = {'username': args.username, 'password': args.password}
    else:
        creds = None

    client = Client(rucio_host=args.host, auth_host=args.auth_host,
                    account=args.account,
                    auth_type=args.auth_strategy, creds=creds,
                    ca_cert=args.ca_certificate, timeout=args.timeout)
    return client


@exception_handler
def ping(args):
    """
    Pings a Rucio server.
    """
    client = get_client(args)
    server_info = client.ping()
    if server_info:
        print server_info['version']
        return SUCCESS
    logger.error('Ping failed')
    return FAILURE


@exception_handler
def whoami_account(args):
    """
    %(prog)s show [options] <field1=value1 field2=value2 ...>

    Show extended information of a given account
    """
    client = get_client(args)
    info = client.whoami()
    for k in info:
        print k.ljust(10) + ' : ' + str(info[k])
    return SUCCESS


@exception_handler
def add_file(args):
    """
    %(prog)s show [options] <field1=value1 field2=value2 ...>

    Add file.
    """
    client = get_client(args)
    scope = args.scope
    lfn = args.lfn
    if scope is None:
        scope, lfn = extract_scope(lfn)
    client.add_file(rse=args.rse, scope=scope, lfn=lfn)
    print 'Added new file replica: %s-%s' % (args.rse, args.lfn)
    return SUCCESS


@exception_handler
def list_dataset_replicas(args):
    """
    %(prog)s list [options] <field1=value1 field2=value2 ...>

    List file replicas
    """
    client = get_client(args)
    scope, name = extract_scope(args.did)
    dids = client.scope_list(scope=scope, name=name, recursive=True)
    datasets = {}
    result = {}
    for d in dids:
        if d['type'] == 'FILE':
            dsn = '%s:%s' % (d['parent']['scope'], d['parent']['name'])
            if dsn not in datasets:
                datasets[dsn] = 0
            datasets[dsn] += 1
    for dsn in datasets:
        scope, name = extract_scope(dsn)
        replicas = client.list_replicas([{'scope': scope, 'name': name}])
        result[dsn] = {}
        for replica in replicas:
            for rse in replica['rses']:
                if rse not in result[dsn]:
                    result[dsn][rse] = 0
                if replica['rses'][rse] != []:
                    result[dsn][rse] += 1
    for dsn in result:
        print 'Dataset %s' % (dsn)
        print '{0:40} {1:6} {2:6}'.format('RSE', 'Found', 'Total')
        for rse in result[dsn]:
            print '{0:40} {1:6d} {2:6d}'.format(rse, result[dsn][rse], datasets[dsn])
    return SUCCESS


@exception_handler
def list_file_replicas(args):
    """
    %(prog)s list [options] <field1=value1 field2=value2 ...>

    List file replicas
    """
    client = get_client(args)
    protocols = None
    if args.protocols:
        protocols = args.protocols.split(',')

    dids = []
    rse_dict = {}
    if args.selected_rse and args.list_collections:
        print 'Cannot use --rse with --list_collections option'
        return FAILURE
    if args.list_collections and len(args.dids) > 1:
        print 'Cannot use --list_collections option with multiple dids'
        return FAILURE

    for did in args.dids:
        scope, name = extract_scope(did)
        dids.append({'scope': scope, 'name': name})
    replicas = client.list_replicas(dids, schemes=protocols, all_states=args.all_states)
    if not args.list_collections:
        print 'Scope\tName\t\t\tFilesize\tadler32\tReplicas'
    for replica in replicas:
        if 'bytes' in replica:
            str = '%s\t%s\t%s\t%s\t' % (replica['scope'], replica['name'], replica['bytes'], replica['adler32'])
            for rse in replica['rses']:
                if args.list_collections:
                    if rse not in rse_dict:
                        rse_dict[rse] = 0
                    if replica['rses'][rse] != []:
                        rse_dict[rse] += 1
                else:
                    line = '%s%s\t:\t' % (str, rse)
                    for pfn in replica['rses'][rse]:
                        if args.selected_rse:
                            if rse == args.selected_rse:
                                output = '%s%s' % (line, pfn)
                                print output.expandtabs()
                                line = len(line.expandtabs()) * ' '
                                str = len(str.expandtabs()) * ' '
                        else:
                            output = '%s%s' % (line, pfn)
                            print output.expandtabs()
                            line = len(line.expandtabs()) * ' '
                            str = len(str.expandtabs()) * ' '
        elif not args.list_collections:
            str = '%s\t%s\t%s\t%s\t%s' % (replica['scope'], replica['name'], '???', '???', 'Unavalaible')
            print str.expandtabs()
    if args.list_collections:
        nbfiles = len([i for i in client.list_files(dids[0]['scope'], dids[0]['name'])])
        print '{0:40} {1:6} {2:6}'.format('RSE', 'Found', 'Total')
        print '-'*54
        sorted_key = rse_dict.keys()
        sorted_key.sort()
        for rse in sorted_key:
            print '{0:40} {1:6d} {2:6d}'.format(rse, rse_dict[rse], nbfiles)
    return SUCCESS


@exception_handler
def add_dataset(args):
    """
    %(prog)s add-dataset [options] <dsn>

    Add a dataset identifier.
    """
    client = get_client(args)
    scope, name = extract_scope(args.did)
    client.add_dataset(scope=scope, name=name, statuses={'monotonic': args.monotonic})
    print 'Added %s:%s' % (scope, name)
    return SUCCESS


@exception_handler
def add_container(args):
    """
    %(prog)s add-container [options] <dsn>

    Add a container identifier.
    """
    client = get_client(args)
    scope, name = extract_scope(args.did)
    client.add_container(scope=scope, name=name, statuses={'monotonic': args.monotonic})
    print 'Added %s:%s' % (scope, name)
    return SUCCESS


@exception_handler
def attach(args):
    """
    %(prog)s attach [options] <field1=value1 field2=value2 ...>

    Attach a data identifier.
    """
    client = get_client(args)
    scope, name = extract_scope(args.todid)
    dids = []
    for did in args.dids:
        cscope, cname = extract_scope(did)
        dids.append({'scope': cscope, 'name': cname})
    client.attach_dids(scope=scope, name=name, dids=dids)
    print 'DIDs successfully attached to %s:%s' % (scope, name)
    return SUCCESS


@exception_handler
def detach(args):
    """
    %(prog)s detach [options] <field1=value1 field2=value2 ...>

    Detach data identifier.
    """
    client = get_client(args)
    scope, name = extract_scope(args.fromdid)
    dids = []
    for did in args.dids:
        cscope, cname = extract_scope(did)
        dids.append({'scope': cscope, 'name': cname})
    client.detach_dids(scope=scope, name=name, dids=dids)
    return SUCCESS


@exception_handler
def list_dids(args):
    """
    %(prog)s list-dids scope[:*|:name] [--filter 'key=value' | --recursive]

    List the data identifiers for a given scope.
    """
    client = get_client(args)
    filters = {}
    type = 'collection'
    if args.filter:
        if args.recursive:
            logger.error('Option recursive and filter cannot be used together')
            return FAILURE
        else:
            try:
                for key, value in [(a.split('=')[0], a.split('=')[1]) for a in args.filter.split(',')]:
                    if key == 'type':
                        if value.upper() in ['ALL', 'COLLECTION', 'CONTAINER', 'DATASET', 'FILE']:
                            type = value.lower()
                        else:
                            logger.error('{0} is not a valid type. Valid types are {1}'.format(value, ['ALL', 'COLLECTION', 'CONTAINER', 'DATASET', 'FILE']))
                            return FAILURE
                    else:
                        filters[key] = value
            except Exception:
                logger.error("Invalid Filter. Filter must be 'key=value'")
                return FAILURE
    try:
        scope, name = extract_scope(args.did[0])
        if name ==  '':
            name = '*'
    except InvalidObject:
        scope = args.did[0]
        name = '*'
    if scope not in client.list_scopes():
        logger.error('Scope not found')
        return FAILURE
    if name.find('*') > -1:
        if args.recursive:
            logger.error('Option recursive cannot be used with wildcards')
            return FAILURE
        elif ('name' in filters) and (name != '*'):
            logger.error('You cannot use a wildcard query and a filter by name')
            return FAILURE
        filters['name'] = name
        for did in client.list_dids(scope, filters=filters, type=type):
            print '%s:%s [%s]' % (scope, did, type.upper())
    else:
        dids = client.scope_list(scope=scope, name=name, recursive=args.recursive)
        for d in dids:
            if d['level'] == 0:
                print '%(scope)s:%(name)s [%(type)s]' % d
            else:
                print '|    ' * d['level'] + '|- %(scope)s:%(name)s [%(type)s]' % d
    return SUCCESS


@exception_handler
def list_scopes(args):
    """
    %(prog)s list-scopes <scope>

    List scopes.
    """
    # For the moment..
    client = get_client(args)
    scopes = client.list_scopes()
    for scope in scopes:
        print scope
    return SUCCESS


@exception_handler
def scope_list(args):
    """
    %(prog)s scope_list <scope>

    List all data identifiers in given scope.
    """
    client = get_client(args)
    dids = client.scope_list(scope=args.scope)
    for d in dids:
        print '%(scope)s:%(name)s [%(type)s]' % d
    return SUCCESS


@exception_handler
def list_files(args):
    """
    %(prog)s list-files [options] <field1=value1 field2=value2 ...>

    List data identifier contents.
    """
    client = get_client(args)
    for did in args.dids:
        scope, name = extract_scope(did)
        for file in client.list_files(scope=scope, name=name):
            print '%(scope)s:%(name)s\t%(bytes)s\t%(adler32)s\t%(guid)s' % file  # %(size)s\t%(checksum)s
    return SUCCESS


@exception_handler
def list_parent_dids(args):
    """
    %(prog)s list-parent-dids

    List parent data identifier.
    """
    client = get_client(args)
    scope, name = extract_scope(args.did)
    for dataset in client.list_parent_dids(scope=scope, name=name):
        print '%s:%s [%s]' % (dataset['scope'], dataset['name'], dataset['type'])
    return SUCCESS


@exception_handler
def close(args):
    """
    %(prog)s close [options] <field1=value1 field2=value2 ...>

    Close data identifier.
    """
    client = get_client(args)
    for did in args.dids:
        scope, name = extract_scope(did)
        client.set_status(scope=scope, name=name, open=False)
        print '%(scope)s:%(name)s has been closed.' % locals()
    return SUCCESS


@exception_handler
def stat(args):
    """
    %(prog)s stat [options] <field1=value1 field2=value2 ...>

    List attributes and statuses about data identifiers..
    """
    client = get_client(args)
    for did in args.dids:
        scope, name = extract_scope(did)
        info = client.get_did(scope=scope, name=name)
        for k, v in info.iteritems():
            print '%(k)s: %(v)s' % locals()
    return SUCCESS


def delete(args):
    """
    %(prog)s delete [options] <field1=value1 field2=value2 ...>

    Delete data identifier.
    """
    raise NotImplementedError('operation not implemented (delete).')


def __get_dataset(args):
    '''Parse helper for upload'''
    dsscope = None
    dsname = None
    for a in args:
        if a.count(':') == 1:
            if dsscope:
                raise Exception("Only one dataset should be given")
            else:
                dsscope, dsname = a.split(':')
    return dsscope, dsname


def __get_files(args):
    '''Parse helper for upload'''
    files = []
    for a in args:
        if os.path.isfile(a):
            files.append(a)
        if os.path.isdir(a):
            dname, subdirs, fnames = os.walk(a).next()
            for f in fnames:
                files.append(os.path.join(dname, f))
    return files


def upload(args):
    """
    rucio upload [scope:datasetname] [folder/] [files1 file2 file3]
    %(prog)s upload [options] <field1=value1 field2=value2 ...>

    Upload files into Rucio
    """
    client = get_client(args)
    try:
        dsscope, dsname = __get_dataset(args.args)    # None, None if no dataset given
    except Exception:
        logger.error('rucio upload only allows to upload files to one dataset, more than one provided.')
        return FAILURE
    files = __get_files(args.args)               # a list of file names (even if a directory is given)

    list_files = []
    files_to_list = []
    lfns = {}
    revert_dict = {}
    if args.scope:
        fscope = args.scope
    else:
        fscope = 'user.' + client.account
    if fscope not in client.list_scopes_for_account(client.account):
        logger.error("Cannot guess the scope for the files. You must specify one with --scope option. The scope must be one of: " + ', '.join(client.list_scopes_for_account(client.account)))
        return FAILURE

    for name in files:
        try:
            size = os.stat(name).st_size
            checksum = adler32(name)
            # logger.debug('Extracting filesize (%s) and checksum (%s) for file %s:%s' % (str(size), checksum, args.scope, os.path.basename(name)))
            files_to_list.append({'scope': fscope, 'name': os.path.basename(name)})
            list_files.append({'scope': fscope, 'name': os.path.basename(name), 'bytes': size, 'adler32': checksum, 'state': 'C', 'meta': {'guid': generate_uuid()}})
            if not os.path.dirname(name) in lfns:
                lfns[os.path.dirname(name)] = []
            lfns[os.path.dirname(name)].append({'name': os.path.basename(name), 'scope': args.scope, 'adler32': checksum, 'filesize': size})
            revert_dict[args.scope, os.path.basename(name)] = os.path.dirname(name)

        except OSError, e:
            logger.error(e)
            logger.error("No operation will be performed. Exiting!")
            return FAILURE

    rse_settings = rsemgr.get_rse_info(args.rse)
    if rse_settings['availability_write'] != 1:
        logger.critical('RSE is not available for write now')
        return FAILURE

    if args.account is None:
        account = client.whoami()['account']
    else:
        account = args.account
    logger.debug('Using account %s' % (account))

    if dsscope and dsname:
        if files_to_list.count({'scope': dsscope, 'name': dsname}) > 0:
            # There is a file with the name of the destination dataset.
            logger.error('scope:name for the files must be different from scope:name for the destination dataset. {0}:{1}'.format(dsscope, dsname))
            return FAILURE
        try:
            client.add_dataset(scope=dsscope, name=dsname, rules=[{'account': client.account, 'copies': 1, 'rse_expression': args.rse, 'grouping': 'DATASET'}])
            logger.info('Dataset successfully created')
        except DataIdentifierAlreadyExists:
            # TODO: Need to check the rules thing!!
            logger.warning("The dataset name already exist")

    # Adding files to the catalog
    for f in list_files:
        try:  # If the did already exist in the catalog, only shold be upload if the checksum is the same
            meta = client.get_metadata(f['scope'], f['name'])
            logger.warning("The file {0}:{1} already exist in the catalog and will not be added.".format(f['scope'], f['name']))
            if rsemgr.exists(rse_settings=rse_settings, files={'name': f['name'], 'scope': f['scope']}):
                logger.warning('File {0}:{1} already exists on RSE. Will not try to reupload'.format(f['scope'], f['name']))
            else:
                if meta['adler32'] == f['adler32']:
                    logger.info('Local files and file %s:%s recorded in Rucio have the same checksum. Will try the upload' % (f['scope'], f['name']))
                    directory = revert_dict[f['scope'], f['name']]
                    rsemgr.upload(rse_settings=rse_settings, lfns=[{'name': f['name'], 'scope': f['scope'], 'adler32': f['adler32'], 'filesize': f['bytes']}], source_dir=directory)
                    logger.info('File %s:%s successfully uploaded on the storage' % (f['scope'], f['name']))
                else:
                    raise DataIdentifierAlreadyExists

        except DataIdentifierNotFound:
            try:
                logger.info('Adding replicas in Rucio catalog')
                client.add_replicas(files=[f], rse=args.rse)
                logger.info('Replicas successfully added')
                if not dsscope:
                    # only need to add rules for files if no dataset is given
                    logger.info('Adding replication rule on RSE {0} for the file {1}:{2}'.format(args.rse, f['scope'], f['name']))
                    client.add_replication_rule([f], copies=1, rse_expression=args.rse)
                directory = revert_dict[f['scope'], f['name']]
                rsemgr.upload(rse_settings=rse_settings, lfns=[{'name': f['name'], 'scope': f['scope'], 'adler32': f['adler32'], 'filesize': f['bytes']}], source_dir=directory)
                logger.info('File {0}:{1} successfully uploaded on the storage'.format(f['scope'], f['name']))
            except (Duplicate, FileAlreadyExists), e:
                logger.warning(e)
                return FAILURE
            except RessourceTemporaryUnavailable, e:
                logger.error(e)
                return FAILURE
        except DataIdentifierAlreadyExists, e:
            logger.debug(e)
            logger.error("Some of the files already exist in the catalog. No one will be added.")
    if dsname:
        # A dataset is provided. Must add the files to the dataset.
        for f in list_files:
            try:
                client.add_files_to_dataset(scope=dsscope, name=dsname, files=[f])
            except Exception, e:
                logger.warning('Failed to attach file {0} to the dataset'.format(f))
                logger.warning(e)
                logger.warning("Continuing with the next one")

    replicas = []
    replica_dictionary = {}
    for rep in client.list_replicas(files_to_list):
        replica_dictionary[rep['scope'], rep['name']] = rep['rses'].keys()
    for file in list_files:
        if (file['scope'], file['name']) not in replica_dictionary:
            file['state'] = 'A'
            replicas.append(file)
        elif args.rse not in replica_dictionary[file['scope'], file['name']]:
            file['state'] = 'A'
            replicas.append(file)
    if replicas != []:
        logger.info('Will update the file replicas states')
        try:
            client.update_replicas_states(rse=args.rse, files=replicas)
        except AccessDenied, e:
            logger.info(e)
            return FAILURE
        logger.info('File replicas states successfully updated')
    return SUCCESS


def download(args):
    """
    %(prog)s download [options] <field1=value1 field2=value2 ...>

    Download files from Rucio
    """
    client = get_client(args)
    rse_dict = {}
    summary = {}
    for did in args.dids:
        try:
            scope, name = did.split(':')
            logger.info('Starting download for %s:%s' % (scope, name))
            summary['%s:%s' % (scope, name)] = {}
            logger.debug('Getting the list of replicas')
            files = client.list_replicas([{'scope': scope, 'name': name}])
            for file in files:
                if os.path.isfile('%s/%s/%s' % (args.dir, file['scope'], file['name'])):
                    logger.info('File %s:%s already exists locally' % (file['scope'], file['name']))
                    summary['%s:%s' % (scope, name)]['%s:%s' % (file['scope'], file['name'])] = 2
                else:
                    summary['%s:%s' % (scope, name)]['%s:%s' % (file['scope'], file['name'])] = 0
                    list_rses = file['rses'].keys()
                    random.shuffle(list_rses)
                    logger.debug('Choosing RSE')
                    index = 0
                    for rse in list_rses:
                        if rse not in rse_dict:
                            rse_dict[rse] = rsemgr.get_rse_info(rse)
                        if rse_dict[rse]['availability_read']:
                            logger.debug('Getting file %s:%s from %s' % (file['scope'], file['name'], rse))
                            try:
                                rsemgr.download(rse_dict[rse], files=[{'name': file['name'], 'scope': file['scope'], 'adler32': file['adler32']}, ], dest_dir=args.dir, printstatements=True)
                                logger.info('File %s:%s successfully downloaded from %s' % (file['scope'], file['name'], rse))
                                summary['%s:%s' % (scope, name)]['%s:%s' % (file['scope'], file['name'])] = 1
                                break
                            except Exception, e:
                                logger.warning(e)
                                index += 1
                                if index != len(rse):
                                    logger.debug('Will retry download on an other RSE')
                    if summary['%s:%s' % (scope, name)]['%s:%s' % (file['scope'], file['name'])] == 0:
                        logger.error('Cannot download file %s:%s' % (file['scope'], file['name']))
            logger.info('Download operation for %s:%s done' % (scope, name))
        except ValueError, e:
            logger.error('ERROR cannot extract the scope and name from %s : [%s]' % (did, e))
            return FAILURE
        except Exception, e:
            logger.error('Failed to download %(scope)s:%(name)s' % locals())
            logger.error(e)
    print '----------------------------------'
    print 'Download summary'
    for did in summary:
        print 'DID %s' % (did)
        total_files = len(summary[did])
        downloaded_files = 0
        local_files = 0
        for file in summary[did]:
            if summary[did][file] == 1:
                downloaded_files += 1
            elif summary[did][file] == 2:
                local_files += 1


@exception_handler
def get_metadata(args):
    """
    %(prog)s get_metadata [options] <field1=value1 field2=value2 ...>

    Get data identifier metadata
    """
    # For the moment..
    client = get_client(args)
    for did in args.dids:
        scope, name = extract_scope(did)
        meta = client.get_metadata(scope=scope, name=name)
        for k in meta:
            print '%s: %s' % (k, meta[k])
    return SUCCESS


@exception_handler
def set_metadata(args):
    """
    %(prog)s set_metadata [options] <field1=value1 field2=value2 ...>

    Set data identifier metadata
    """
    # For the moment..
    client = get_client(args)
    scope, name = extract_scope(args.did)
    client.set_metadata(scope=scope, name=name, key=args.key, value=args.value)
    return SUCCESS


def delete_metadata(args):
    """
    %(prog)s set_metadata [options] <field1=value1 field2=value2 ...>

    Delete data identifier metadata
    """
    # For the moment..
    raise NotImplementedError


@exception_handler
def add_rule(args):
    """
    %(prog)s add-rule <did> <copies> <rse-expression> [options]

    Add a rule to a did.
    """
    client = get_client(args)
    dids = []
    for did in args.dids:
        scope, name = extract_scope(did)
        dids.append({'scope': scope, 'name': name})
    rule_ids = client.add_replication_rule(dids=dids,
                                           copies=args.copies,
                                           rse_expression=args.rse_expression,
                                           weight=args.weight,
                                           lifetime=args.lifetime,
                                           grouping=args.grouping,
                                           account=args.account,
                                           locked=args.locked,
                                           source_replica_expression=args.source_replica_expression,
                                           notify=args.notify)
    for rule in rule_ids:
        print rule
    return SUCCESS


@exception_handler
def delete_rule(args):
    """
    %(prog)s delete-rule [options] <ruleid>

    Delete a rule.
    """
    client = get_client(args)
    if args.purge_replicas:
        client.delete_replication_rule(rule_id=args.rule_id, purge_replicas=True)
    else:
        client.delete_replication_rule(rule_id=args.rule_id, purge_replicas=None)
    return SUCCESS


@exception_handler
def update_rule(args):
    """
    %(prog)s update-rule [options] <ruleid>

    Update a rule.
    """
    client = get_client(args)
    options = {}
    if args.lifetime:
        options['lifetime'] = None if args.lifetime == "None" else int(args.lifetime)
    if args.locked:
        if args.locked == "True":
            options['locked'] = True
        elif args.locked == "False":
            options['locked'] = False
    if args.rule_account:
        options['account'] = args.rule_account
    if args.state_stuck:
        options['state'] = 'STUCK'
    if args.state_suspended:
        options['state'] = 'SUSPENDED'
    client.update_replication_rule(rule_id=args.rule_id, options=options)
    print 'Updated Rule'
    return SUCCESS


@exception_handler
def info_rule(args):
    """
    %(prog)s rule-info [options] <ruleid>

    Retrieve information about a rule.
    """
    client = get_client(args)
    rule = client.get_replication_rule(rule_id=args.rule_id)
    print "Id:                         %s" % rule['id']
    print "Account:                    %s" % rule['account']
    print "Scope:                      %s" % rule['scope']
    print "Name:                       %s" % rule['name']
    print "RSE Expression:             %s" % rule['rse_expression']
    print "Copies:                     %s" % rule['copies']
    print "State:                      %s" % rule['state']
    print "Locks OK/REPLICATING/STUCK: %s/%s/%s" % (rule['locks_ok_cnt'], rule['locks_replicating_cnt'], rule['locks_stuck_cnt'])
    print "Grouping:                   %s" % rule['grouping']
    print "Expires at:                 %s" % rule['expires_at']
    print "Locked:                     %s" % rule['locked']
    print "Weight:                     %s" % rule['weight']
    print "Created at:                 %s" % rule['created_at']
    print "Updated at:                 %s" % rule['updated_at']
    print "Error:                      %s" % rule['error']
    print "Subscription Id:            %s" % rule['subscription_id']
    print "Source replica expression:  %s" % rule['source_replica_expression']
    return SUCCESS


@exception_handler
def list_rules(args):
    """
    %(prog)s list-rules ...

    List rules.
    """
    client = get_client(args)
    if args.rule_id:
        rules = [client.get_replication_rule(args.rule_id)]
    elif args.file:
        scope, name = extract_scope(args.file)
        rules = client.list_associated_rules_for_file(scope=scope, name=name)
    elif args.did:
        scope, name = extract_scope(args.did)
        client.get_metadata(scope=scope, name=name)
        rules = client.list_did_rules(scope=scope, name=name)
    elif args.rule_account:
        rules = client.list_account_rules(account=args.rule_account)
    elif args.subscription:
        account = args.subscription[0]
        name = args.subscription[1]
        rules = client.list_subscription_rules(account=account, name=name)
    else:
        print 'At least one option has to be given. Use -h to list the options.'
        return FAILURE

    print "ID (account) SCOPE:NAME: STATE [LOCKS_OK/REPLICATING/STUCK], RSE_EXPRESSION, COPIES"
    print "==================================================================================="
    for rule in rules:
        print "%s (%s) %s:%s: %s[%s/%s/%s], \"%s\", %s " % (rule['id'], rule['account'], rule['scope'], rule['name'], rule['state'], rule['locks_ok_cnt'], rule['locks_replicating_cnt'], rule['locks_stuck_cnt'], rule['rse_expression'], rule['copies'])
    return SUCCESS


@exception_handler
def list_rses(args):
    """
    %(prog)s list [options] <field1=value1 field2=value2 ...>

    List rses.

    """
    client = get_client(args)
    rse_expression = None
    if args.rse_expression:
        rse_expression = args.rse_expression
    rses = client.list_rses(rse_expression)
    for rse in rses:
        print '%(rse)s' % rse
    return SUCCESS


@exception_handler
def list_rse_usage(args):
    """
    %(prog)s list-rse-usage [options] <rse>

    Show the space usage of a given rse

    """
    client = get_client(args)
    usages = client.get_rse_usage(rse=args.rse)
    print 'Usage:'
    print '======'
    for usage in usages:
        skip_free = False
        if usage['source'] in ['rucio', 'reaper']:
            skip_free = True
        for elem in usage:
            if not ((elem == 'free' or elem == 'total') and skip_free):
                print '  ' + elem + ': ' + str(usage[elem])
        print '  ======'
    return SUCCESS


@exception_handler
def list_account_limits(args):
    """
    %(prog)s list [options] <field1=value1 field2=value2 ...>

    List account limits.

    """
    client = get_client(args)
    if args.rse:
        limits = client.get_account_limit(account=args.limit_account, rse=args.rse)
    else:
        limits = client.get_account_limits(account=args.limit_account)
    print "RSE: limit (bytes)"
    print "=================="
    for limit in limits.items():
        print "%s: %s" % limit
    return SUCCESS


@exception_handler
def list_account_usage(args):
    """
    %(prog)s list [options] <field1=value1 field2=value2 ...>

    List account usage.

    """
    client = get_client(args)
    if args.rse:
        usage = client.get_account_usage(account=args.usage_account, rse=args.rse)
    else:
        usage = client.get_account_usage(account=args.usage_account)
    print "RSE: usage (bytes), limit (bytes), quota_left (bytes)"
    print "====================================================="
    for item in usage:
        print "%s: %s, %s, %s" % (item['rse'], item['bytes'], item['bytes_limit'], item['bytes_remaining'])
    return SUCCESS


@exception_handler
def list_datasets_rse(args):
    """
    %(prog)s list [options] <field1=value1 field2=value2 ...>

    List the datasets in a site.

    """
    client = get_client(args)
    dsns = list(set(['%s:%s' % (dsn['scope'], dsn['name']) for dsn in client.get_dataset_locks_by_rse(args.rse)]))
    dsns.sort()
    for dsn in dsns:
        print dsn
    return SUCCESS


def test_server(args):
    """"
    %(prog)s test-server [options] <field1=value1 field2=value2 ...>
    Test the client against a server.
    """
    import nose
    config = nose.config.Config()
    config.verbosity = 2
    nose.run(argv=sys.argv[1:], defaultTest='rucio.tests.test_rucio_server', config=config)
    return SUCCESS


if __name__ == '__main__':
    usage = """
usage: %(prog)s <command> [options] [args]

Commands:

    help <command>  Output help for one of the commands below


"""
    oparser = argparse.ArgumentParser(prog=os.path.basename(sys.argv[0]), add_help=True)
    subparsers = oparser.add_subparsers()

    # Main arguments
    oparser.add_argument('--version', action='version', version='%(prog)s ' + version.version_string())
    oparser.add_argument('--verbose', '-v', default=False, action='store_true', help="Print more verbose output")
    oparser.add_argument('-H', '--host', dest="host", metavar="ADDRESS", help="The Rucio API host")
    oparser.add_argument('--auth-host', dest="auth_host", metavar="ADDRESS", help="The Rucio Authentication host")
    oparser.add_argument('-a', '--account', dest="account", metavar="ACCOUNT", help="Rucio account to use")
    oparser.add_argument('-S', '--auth-strategy', dest="auth_strategy", default=None, help="Authentication strategy (userpass or x509 or ...)")
    oparser.add_argument('-T', '--timeout', dest="timeout", type=float, default=None, help="Set all timeout values to SECONDS")

    # Options for the userpass auth_strategy
    oparser.add_argument('-u', '--user', dest='username', default=None, help='username')
    oparser.add_argument('-pwd', '--password', dest='password', default=None, help='password')

    # Options for the x509  auth_strategy
    oparser.add_argument('--certificate', dest='certificate', default=None, help='Client certificate file')
    oparser.add_argument('--ca-certificate', dest='ca_certificate', default=None, help='CA certificate to verify peer against (SSL)')

    # Ping command
    ping_parser = subparsers.add_parser('ping', help='Ping Rucio server')
    ping_parser.set_defaults(which='ping')

    # The whoami command
    whoami_parser = subparsers.add_parser('whoami', help='Get information about account whose token is used')
    whoami_parser.set_defaults(which='whoami_account')

    # The list-file-replicas command
    list_file_replicas_parser = subparsers.add_parser('list-file-replicas', help='List file replicas', description='This method allows to list all the replicas of a given Data IDentifier (DID).\
                                                 The only mandatory parameter is the DID which can be a container/dataset/files. By default all the files replicas in state available are returned. Various options can be used :')
    list_file_replicas_parser.set_defaults(which='list_file_replicas')
    list_file_replicas_parser.add_argument('--protocols', dest='protocols', action='store', help='List of comma separated protocols', required=False)
    list_file_replicas_parser.add_argument('--all_states', dest='all_states', action='store_true', default=False, help='To select all replicas (including unavailable ones)', required=False)
    list_file_replicas_parser.add_argument('--list_collections', dest='list_collections', action='store_true', default=False, help='To have the number of files of the dataset by site', required=False)
    list_file_replicas_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')
    list_file_replicas_parser.add_argument('--rse', dest='selected_rse', default=False, action='store', help='Target RSE', required=False)

    # The list-dataset-replicas command
    list_dataset_replicas_parser = subparsers.add_parser('list-dataset-replicas', help='List the dataset replicas')
    list_dataset_replicas_parser.set_defaults(which='list_dataset_replicas')
    list_dataset_replicas_parser.add_argument(dest='did', action='store', help='Data IDentifier to search')

    # The add-dataset command
    add_dataset_parser = subparsers.add_parser('add-dataset', help='Add dataset')
    add_dataset_parser.set_defaults(which='add_dataset')
    add_dataset_parser.add_argument('--monotonic', action='store_true', help='Monotonic status to True')
    add_dataset_parser.add_argument(dest='did', action='store', help='Dataset name to add')

    # The add-container command
    add_container_parser = subparsers.add_parser('add-container', help='Add container')
    add_container_parser.set_defaults(which='add_container')
    add_container_parser.add_argument('--monotonic', action='store_true', help='Monotonic status to True')
    add_container_parser.add_argument(dest='did', action='store', help='Container name to add')

    # TODO:
    # delete
    # regexp to validate a rse attribute key / value
    # add meta

    # The attach command
    attach_parser = subparsers.add_parser('attach', help='Attach a list of Data Identifiers (file, dataset or container) to an other Data Identifier (dataset or container)',
                                          description='Attach a list of Data Identifiers (file, dataset or container) to an other Data Identifier (dataset or container)')
    attach_parser.set_defaults(which='attach')
    attach_parser.add_argument(dest='todid', action='store', help='Destination Data IDentifier (either dataset or container)')
    attach_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')

    # The detach command
    detach_parser = subparsers.add_parser('detach', help='Detach a list of Data Identifiers (file, dataset or container) from an other Data Identifier (dataset or container)',
                                          description='Detach a list of Data Identifiers (file, dataset or container) from an other Data Identifier (dataset or container)')
    detach_parser.set_defaults(which='detach')
    detach_parser.add_argument(dest='fromdid', action='store', help='Target data identifier (must be a dataset or container)')
    detach_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')

    # The list command
    list_parser = subparsers.add_parser('list-dids', help='List the data identifiers matching some metadata', description='List the Data IDentifiers matching certain pattern.\
                                         Only the collections (i.e. dataset or container) are returned by default.\
                                         With the filter option, you can specify a list of metadata that the Data IDentifier should match.')
    list_parser.set_defaults(which='list_dids')
    list_parser.add_argument('--recursive', dest='recursive', action='store_true', default=False, help='List data identifiers recursively')
    list_parser.add_argument('--filter', dest='filter', action='store', help='Filter arguments in form `key=value,another_key=next_value`. Valid keys are name, type.')
    list_parser.add_argument(dest='did', nargs=1, action='store', default=None, help='Data IDentifier pattern')

    # The list parent-dids command
    list_parent_parser = subparsers.add_parser('list-parent-dids', help='List parent data identifiers', description='List data identifier parents')
    list_parent_parser.set_defaults(which='list_parent_dids')
    list_parent_parser.add_argument(dest='did', action='store', default=None, help='Data identifier')

    # The list-scopes command
    scope_list_parser = subparsers.add_parser('list-scopes', help='List all available scopes')
    scope_list_parser.set_defaults(which='list_scopes')

    # The close command
    close_parser = subparsers.add_parser('close', help='Close data identifier')
    close_parser.set_defaults(which='close')
    close_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')

    # The stat command
    stat_parser = subparsers.add_parser('stat', help='List attributes and statuses about data identifiers')
    stat_parser.set_defaults(which='stat')
    stat_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')

    # The delete command
    delete_parser = subparsers.add_parser('delete', help='Delete data identifier')
    delete_parser.set_defaults(which='delete')
    delete_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')
    delete_parser.add_argument('--from', dest='from', default=None, action='store', help='Target data identifier')

    # The list_files command
    list_files_parser = subparsers.add_parser('list-files', help='List data identifier contents', description='List all the files in a Data IDentifier (DID). The DID can be a container, dataset or a file.\
                                                                  What is returned is a list of files in the DID with : <scope>:<name>\t<filesize>\t<checksum>\t<guid>')
    list_files_parser.set_defaults(which='list_files')
    list_files_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')

    # The upload subparser
    upload_parser = subparsers.add_parser('upload', help='Upload method')
    upload_parser.set_defaults(which='upload')
    upload_parser.add_argument('--rse', dest='rse', action='store', help='Rucio Storage Element (RSE) name', required=True)
    upload_parser.add_argument('--scope', dest='scope', action='store', help='Scope name')  # to be optional after
    upload_parser.add_argument(dest='args', action='store', nargs='+', metavar=('file', 'other_file, directory, scope:dataset_name'), help='files and datasets')

    # The download subparser
    download_parser = subparsers.add_parser('download', help='Download method')
    download_parser.set_defaults(which='download')
    download_parser.add_argument('--dir', dest='dir', default='.', action='store', help='The directory to store the downloaded file.')
    download_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')

    # The get-metadata subparser
    get_metadata_parser = subparsers.add_parser('get-metadata', help='Get metadata for DIDs')
    get_metadata_parser.set_defaults(which='get_metadata')
    get_metadata_parser.add_argument(dest='dids', nargs='+', action='store', help='List of space separated data identifiers')

    # The set-metadata subparser
    set_metadata_parser = subparsers.add_parser('set-metadata', help='set-metadata method')
    set_metadata_parser.set_defaults(which='set_metadata')
    set_metadata_parser.add_argument('--did', dest='did', action='store', help='Data identifier to add', required=True)
    set_metadata_parser.add_argument('--key', dest='key', action='store', help='Attribute key', required=True)
    set_metadata_parser.add_argument('--value', dest='value', action='store', help='Attribute value', required=True)

    # The delete-metadata subparser
    delete_metadata_parser = subparsers.add_parser('delete-metadata', help='Delete metadata')
    delete_metadata_parser.set_defaults(which='delete_metadata')

    # The list-rse-usage subparser
    list_rse_usage_parser = subparsers.add_parser('list-rse-usage', help='list-rse-usage method')
    list_rse_usage_parser.set_defaults(which='list_rse_usage')
    list_rse_usage_parser.add_argument(dest='rse', action='store', help='Rucio Storage Element (RSE) name')
    list_rse_usage_parser.add_argument('--history', dest='history', default=False, action='store', help='List rse usage history')

    # The list-account-usage subparser
    list_account_usage_parser = subparsers.add_parser('list-account-usage', help='list-account-usage method')
    list_account_usage_parser.set_defaults(which='list_account_usage')
    list_account_usage_parser.add_argument(dest='usage_account', action='store', help='Account name')
    list_account_usage_parser.add_argument('--rse', action='store', help='Show usage for this rse')

    # The list-account-limits subparser
    list_account_limits_parser = subparsers.add_parser('list-account-limits', help='List account limits on RSEs')
    list_account_limits_parser.set_defaults(which='list_account_limits')
    list_account_limits_parser.add_argument('limit_account', action='store', help='Account name')
    list_account_limits_parser.add_argument('--rse', dest='rse', action='store', help='RSE name')

    # Add replication rule subparser
    add_rule_parser = subparsers.add_parser('add-rule', help='Add replication rule')
    add_rule_parser.set_defaults(which='add_rule')
    add_rule_parser.add_argument(dest='dids', action='store', nargs='+', help='DID(s) to apply the rule to')
    add_rule_parser.add_argument(dest='copies', action='store', type=int, help='Number of copies')
    add_rule_parser.add_argument(dest='rse_expression', action='store', help='RSE Expression')
    add_rule_parser.add_argument('--weight', dest='weight', action='store', help='RSE Weight')
    add_rule_parser.add_argument('--lifetime', dest='lifetime', action='store', type=int, help='Rule lifetime (in seconds)')
    add_rule_parser.add_argument('--grouping', dest='grouping', action='store', choices=['DATASET', 'ALL', 'NONE'], help='Rule grouping')
    add_rule_parser.add_argument('--locked', dest='locked', action='store_true', help='Rule locking')
    add_rule_parser.add_argument('--source-replica-expression', dest='source_replica_expression', action='store', help='Source Replica Expression')
    add_rule_parser.add_argument('--notify', dest='notify', action='store', help='Notification strategy : Y (Yes), N (No), C (Close)')

    # Delete replication rule subparser
    delete_rule_parser = subparsers.add_parser('delete-rule', help='Delete replication rule')
    delete_rule_parser.set_defaults(which='delete_rule')
    delete_rule_parser.add_argument(dest='rule_id', action='store', help='Rule id')
    delete_rule_parser.add_argument('--purge-replicas', dest='purge_replicas', action='store_true', help='Purge rule replicas')

    # Info replication rule subparser
    info_rule_parser = subparsers.add_parser('rule-info', help='Retrieve information about a rule')
    info_rule_parser.set_defaults(which='info_rule')
    info_rule_parser.add_argument(dest='rule_id', action='store', help='Rule id')

    # The list_rules command
    list_rules_parser = subparsers.add_parser('list-rules', help='List replication rules')
    list_rules_parser.set_defaults(which='list_rules')
    list_rules_parser.add_argument(dest='did', action='store', nargs='?', default=None, help='List by did')
    list_rules_parser.add_argument('--rule', dest='rule_id', action='store', help='List by rule id')
    list_rules_parser.add_argument('--file', dest='file', action='store', help='List associated rules of an affected file')
    list_rules_parser.add_argument('--account', dest='rule_account', action='store', help='List by account')
    list_rules_parser.add_argument('--subscription', dest='subscription', action='store', help='List by account and subscription name', metavar=('ACCOUNT', 'SUBSCRIPTION'), nargs=2)

    # The update_rule command
    update_rule_parser = subparsers.add_parser('update-rule', help='Update replication rule')
    update_rule_parser.set_defaults(which='update_rule')
    update_rule_parser.add_argument(dest='rule_id', action='store', help='Rule id')
    update_rule_parser.add_argument('--lifetime', dest='lifetime', action='store', help='Lifetime in seconds.')
    update_rule_parser.add_argument('--locked', dest='locked', action='store', help='Locked (True/False).')
    update_rule_parser.add_argument('--account', dest='rule_account', action='store', help='Account to change.')
    update_rule_parser.add_argument('--stuck', dest='state_stuck', action='store_true', help='Set state to STUCK.')
    update_rule_parser.add_argument('--suspend', dest='state_suspended', action='store_true', help='Set state to SUSPENDED.')

    # The list-rses command
    list_rses_parser = subparsers.add_parser('list-rses', help='List RSEs')
    list_rses_parser.set_defaults(which='list_rses')
    list_rses_parser.add_argument('--expression', dest='rse_expression', action='store', help='RSE Expression')

    # The list-datasets-site command
    list_datasets_rse_parser = subparsers.add_parser('list-datasets-rse', help='List all the datasets at a Rucio Storage Element', description='This method allows to list all the datasets on a given Rucio Storage Element.')
    list_datasets_rse_parser.set_defaults(which='list_datasets_rse')
    list_datasets_rse_parser.add_argument(dest='rse', action='store', default=None, help='The RSE name')

    # The test-server command
    test_server_parser = subparsers.add_parser('test-server', help='Test Server')
    test_server_parser.set_defaults(which='test_server')

    argcomplete.autocomplete(oparser)

    if len(sys.argv) == 1:
        oparser.print_help()
        sys.exit(FAILURE)

    args = oparser.parse_args(sys.argv[1:])

    commands = {'add_container': add_container,
                'add_dataset': add_dataset,
                'add_rule': add_rule,
                'attach': attach,
                'close': close,
                'delete': delete,
                'delete_metadata': delete_metadata,
                'delete_rule': delete_rule,
                'detach': detach,
                'download': download,
                'get_metadata': get_metadata,
                'info_rule': info_rule,
                'list_account_limits': list_account_limits,
                'list_account_usage': list_account_usage,
                'list_datasets_rse': list_datasets_rse,
                'list_parent_dids': list_parent_dids,
                'list_files': list_files,
                'list_dids': list_dids,
                'list_dataset_replicas': list_dataset_replicas,
                'list_file_replicas': list_file_replicas,
                'list_rses': list_rses,
                'list_rse_usage': list_rse_usage,
                'list_rules': list_rules,
                'list_scopes': list_scopes,
                'ping': ping,
                'set_metadata': set_metadata,
                'stat': stat,
                'test_server': test_server,
                'update_rule': update_rule,
                'upload': upload,
                'whoami_account': whoami_account}

    try:
        if args.verbose:
            logger.setLevel(logging.DEBUG)
        start_time = time.time()
        command = commands.get(args.which)
        result = command(args)
        end_time = time.time()
        if args.verbose:
            print "Completed in %-0.4f sec." % (end_time - start_time)
        sys.exit(result)
    except (RuntimeError, NotImplementedError), e:
        print >> sys.stderr, "ERROR: ", e
        sys.exit(FAILURE)
